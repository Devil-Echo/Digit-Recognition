{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed_forward_fully_connected neural network\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "train = datasets.MNIST('', train=True, download=True,\n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test = datasets.MNIST('', train=False, download=True,\n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64) #fully__connected_flat_layer(input,output)\n",
    "        self.fc2 = nn.Linear(64, 64) # first layer has 28*28 features/pixels \n",
    "        self.fc3 = nn.Linear(64, 64) \n",
    "        self.fc4 = nn.Linear(64, 10) # 3 hidden layers, the 2nd layer takes 64 inputs as output\n",
    "                                     # of the previous layer is 64,in the end we have 10 outputs \n",
    "                                     # for the 10 digits\n",
    "                \n",
    "    def forward(self, x): # data transfer path\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x)) # here we can put conditions(if/else, etc) to generate some really advanced models\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x) # no rectified linear activator function for output\n",
    "        \n",
    "        return F.log_softmax(x, dim=1) # probability distribution for output\n",
    "                                       # dim=0 implies distribution across batches\n",
    "                                       # dim=1 implies the same across output\n",
    "    \n",
    "        \n",
    "net = Net()\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand([28,28])\n",
    "X = X.view([-1,28*28]) # -1 for any size array or tensor (unknown shape)\n",
    "                       # it is basically [1,784] here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3166, -2.2047, -2.3956, -2.3082, -2.3013, -2.3055, -2.3844, -2.3041,\n",
       "         -2.1904, -2.3346]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0036, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0062, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0374, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001) #(parameters that can be modified, learning rate)\n",
    "\n",
    "EPOCHS = 3 # 3 full passes over the data\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        # data is a batch of featuresets and labels \n",
    "        X, y = data\n",
    "        net.zero_grad()\n",
    "        output = net(X.view([-1, 28*28]))\n",
    "        loss = F.nll_loss(output, y)   # loss calculator, one hot vector, ex-[0,1,0,0]\n",
    "                                       # use mean squared error for one hot vector\n",
    "                                       # here, data is scalar , so we use nll_loss\n",
    "        loss.backward() # backpropagation-apply this loss backwards thru the network's parameters\n",
    "        optimizer.step()  # attempt to optimize weights to account for loss/gradients\n",
    "    print(loss)     # print loss. We hope loss (a measure of wrong-ness) declines! \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.972\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1, 784))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "print(\"Accuracy : \", round(correct/total, 3))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16e11369f88>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X[1].view([28,28]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[1].view(-1,784))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
